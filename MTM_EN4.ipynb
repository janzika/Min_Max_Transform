{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Minimum Transformation Method\n",
    "## <center>An inverse model for inferring surface fluxes and mixing from gridded hydrographic TS data, <br> by Taimoor Sohail and Jan D. Zika\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <center>We use an optimal transport method, minimzing a cost function which respects the volume and mass conservation, and the fundamental physics of mixing in TS space. <br>See also: Jan D Zika et al. (2021) [www.doi.org/10.1175/JCLI-D-20-0355.1 ] for a simpler version of this model which optimizes ocean circulation only.\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __The code is laid out as follows:__\n",
    "#### A) Pre-processing\n",
    "i) Load necessary modules for computation \\\n",
    "ii) Define key parameters\n",
    "#### B) Load Data\n",
    "#### C) Define constraints\n",
    "i) Define Connectivity \\\n",
    "ii) Define weights\n",
    "#### D) Run optimisation\n",
    "#### E) Save Output\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Load necessary modules for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Module to run the minimisation\n",
    "from WM_Methods import MTM\n",
    "## Module to track runtime of cells and loops\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "## Suppress warnings related to division by zero\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "## Module to load files and handle array computations\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "## Modules to plot outputs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "# Specify font properties for plots\n",
    "from matplotlib import rc\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Define key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thermal expansion, haline contraction and true scale factor\n",
    "alph = 1.7657*10**-4\n",
    "bet = 7.5544*10**-4\n",
    "\n",
    "volnorming = 10**15 #normalising coeffcients\n",
    "areanorming = 10**12 #normalising coeffcients\n",
    "ST_scale=bet/alph\n",
    "\n",
    "# Establish basic constants \n",
    "yr2sec = 365.25*24*60*60\n",
    "Cp=4000\n",
    "rho=1024\n",
    "S0=35\n",
    "\n",
    "# Range of years of which 'early' and 'late' are defined\n",
    "dyrs = 10\n",
    "init_early = 1970\n",
    "init_late = 2005\n",
    "Early_period = (np.array([init_early,init_early+dyrs]) - 1970)*12\n",
    "Late_period = (np.array([init_late,init_late+dyrs]) - 1970)*12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## B) Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The data is presented as monthly T-S observations from EN4, from January 1970 to December 2014. The observations have already been binned via Binary Space Partitioning according to a specific criterion. Folowing Sohail et al. (TBD) the BSP partitioning occurs in an xyxyxyx order, shown to minimize variability in the temperature and salinity signals. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.27 s, sys: 277 ms, total: 3.55 s\n",
      "Wall time: 3.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EN4_BSP_data = xr.open_mfdataset('BSP_processed/BSP_EN4_TS_*.nc')\n",
    "\n",
    "## Early Period\n",
    "Part_early = EN4_BSP_data.Partitions.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "SA_early =  EN4_BSP_data.S_mean.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "CT_early = EN4_BSP_data.T_mean.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "V_early = EN4_BSP_data.V_sum.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "A_early = EN4_BSP_data.A_sum.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "\n",
    "\n",
    "## Late Period\n",
    "Part_late = EN4_BSP_data.Partitions.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "SA_late =  EN4_BSP_data.S_mean.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "CT_late = EN4_BSP_data.T_mean.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "V_late = EN4_BSP_data.V_sum.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "A_late = EN4_BSP_data.A_sum.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "\n",
    "Basins = EN4_BSP_data.Basin.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten the early and late variables to a 1D array\n",
    "Vol_1 = V_early.values.flatten()\n",
    "Vol_2 = V_late.values.flatten()\n",
    "S_1 = SA_early.values.flatten()-S0 # Remove reference salinity S0\n",
    "S_2 = SA_late.values.flatten()-S0 # Remove reference salinity S0\n",
    "T_1 = CT_early.values.flatten()\n",
    "T_2 = CT_late.values.flatten()\n",
    "A_1 = A_early.values.flatten()\n",
    "A_2 = A_late.values.flatten()\n",
    "\n",
    "# Do the same for basin index\n",
    "Basin_1 = np.zeros_like(V_early)\n",
    "Basin_2 = np.zeros_like(V_early)\n",
    "Basin_names = []\n",
    "for i in range(np.array(Basins).size):\n",
    "    Basin_1[i,:] = i\n",
    "    Basin_2[i,:] = i\n",
    "    for j in range(V_early.shape[-1]):\n",
    "        #... and for basin name\n",
    "        Basin_names.append(Basins[i])\n",
    "\n",
    "Basin_1_inds = Basin_1.flatten()\n",
    "Basin_2_inds = Basin_2.flatten()\n",
    "\n",
    "#... and for the edges of the BSP bins\n",
    "## Here we calculate the mean TS edges averaged over both early and late times\n",
    "S_start = (0.5*(Part_early.values[:,:,0]+Part_late.values[:,:,0])).flatten()-S0 # Remove reference salinity S0\n",
    "S_end = (0.5*(Part_early.values[:,:,1]+Part_late.values[:,:,1])).flatten()-S0 # Remove reference salinity S0\n",
    "T_start = (0.5*(Part_early.values[:,:,2]+Part_late.values[:,:,2])).flatten()\n",
    "T_end = (0.5*(Part_early.values[:,:,3]+Part_late.values[:,:,3])).flatten()\n",
    "\n",
    "# Any NaNs are zeroed out\n",
    "S_1[np.isnan(S_1)] = 0\n",
    "S_2[np.isnan(S_2)] = 0\n",
    "T_1[np.isnan(T_1)] = 0\n",
    "T_2[np.isnan(T_2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we create the tracers and volumes matrices, which will be fed into the MTM function\n",
    "\n",
    "volumes = np.stack((Vol_1, Vol_2), axis=0)/volnorming # Shape: [2 x N]\n",
    "\n",
    "salinities = np.stack((S_1, S_2), axis=0)\n",
    "temps = np.stack((T_1, T_2), axis=0)\n",
    "\n",
    "tracers = np.stack((salinities, temps),axis=1) # Shape: [2 x M x N], where M = 2 for just T and S, and M>2 for T,S+other tracers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of bins = 1152\n"
     ]
    }
   ],
   "source": [
    "print('Total number of bins =', int(Vol_1.shape[0]))\n",
    "N = int(Vol_1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## C) Define Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Define Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must define whether a BSP bin is allowed to transport volume to another BSP bin. In the simplest case, all bins are allowed to transport to one another - but this yields nonphysical transport across vast distances and TS bounds.\n",
    "To improve on this, two connectivity constraints are used: \n",
    "1) Are the basins adjacent? This is defined via the connectivity array, below\n",
    "2) If YES, do the BSP bins have overlapping (or the same) TS boundaries?\\\n",
    "If yes, the bins are connected. If no, they are not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array defining the connection between the 9 basins;\n",
    "# 1 = connected, 0 = disconnected\n",
    "connectivity_array = np.zeros((Basins.size,Basins.size))\n",
    "\n",
    "connectivity_array[0,:] = [1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "connectivity_array[1,:] = [1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "connectivity_array[2,:] = [0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "connectivity_array[3,:] = [0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
    "connectivity_array[4,:] = [0, 0, 0, 0, 1, 0, 1, 0, 1]\n",
    "connectivity_array[5,:] = [0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
    "connectivity_array[6,:] = [0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
    "connectivity_array[7,:] = [0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
    "connectivity_array[8,:] = [0, 0, 0, 1, 1, 1, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051f397c5c1a4970b494c7ba627cbb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define whether a bin is connected to every other bin\n",
    "# The two constraints used are: are the basins adjacent? \n",
    "# If yes, are the bin indices the same? \n",
    "# If yes, the bins are connected; if no, they are not connected. \n",
    "connected = np.zeros((Vol_1.size, Vol_1.size))\n",
    "\n",
    "for i in tqdm(range(Vol_1.size)):\n",
    "    for j in range(Vol_2.size):\n",
    "        if connectivity_array[int(Basin_1_inds[i]), int(Basin_2_inds[j])]==1:\n",
    "            if Basin_names[i] == Basin_names[j]:\n",
    "                connected[i,j] = 1\n",
    "            elif S_start[i]==S_start[j] and T_start[i]==T_start[j]:\n",
    "                connected[i,j] = 1\n",
    "\n",
    "constraints = connected # Shape: An [N x N] matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Define Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "## We create a weight matrix\n",
    "# Note that the code is very sensitive to the weights we input, and may break (TO BE DEVELOPED)\n",
    "offset = 10**12 # To prevent divide by zero errors\n",
    "weights = np.stack(((ST_scale)/(np.log10(A_2)),1/(np.log10(A_2))), axis=0) # Shape: An [M x N] matrix\n",
    "weights = np.ones_like(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## D) Run Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                    v1.1.13                                    \n",
      "===============================================================================\n",
      "(CVXPY) May 09 04:52:04 PM: Your problem has 149760 variables, 2 constraints, and 0 parameters.\n",
      "(CVXPY) May 09 04:52:06 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) May 09 04:52:06 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) May 09 04:52:06 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 09 04:52:06 PM: Compiling problem (target solver=MOSEK).\n",
      "(CVXPY) May 09 04:52:06 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> MOSEK\n",
      "(CVXPY) May 09 04:52:06 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) May 09 04:52:06 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) May 09 04:52:06 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) May 09 04:52:35 PM: Applying reduction MOSEK\n",
      "(CVXPY) May 09 04:52:35 PM: Finished problem compilation (took 2.898e+01 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 09 04:52:35 PM: Invoking solver MOSEK  to obtain a solution.\n",
      "\n",
      "\n",
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : max             \n",
      "  Type                   : CONIC (conic optimization problem)\n",
      "  Constraints            : 149761          \n",
      "  Cones                  : 1               \n",
      "  Scalar variables       : 154370          \n",
      "  Matrix variables       : 0               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer started.\n",
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : max             \n",
      "  Type                   : CONIC (conic optimization problem)\n",
      "  Constraints            : 149761          \n",
      "  Cones                  : 1               \n",
      "  Scalar variables       : 154370          \n",
      "  Matrix variables       : 0               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer  - threads                : 12              \n",
      "Optimizer  - solved problem         : the dual        \n",
      "Optimizer  - Constraints            : 4128\n",
      "Optimizer  - Cones                  : 1\n",
      "Optimizer  - Scalar variables       : 124940            conic                  : 2058            \n",
      "Optimizer  - Semi-definite variables: 0                 scalarized             : 0               \n",
      "Factor     - setup time             : 0.15              dense det. time        : 0.00            \n",
      "Factor     - ML order time          : 0.06              GP order time          : 0.00            \n",
      "Factor     - nonzeros before factor : 3.78e+05          after factor           : 6.34e+05        \n",
      "Factor     - dense dim.             : 2                 flops                  : 1.21e+08        \n",
      "ITE PFEAS    DFEAS    GFEAS    PRSTATUS   POBJ              DOBJ              MU       TIME  \n",
      "0   0.0e+00  1.4e+02  2.0e+00  0.00e+00   -1.000000000e+00  0.000000000e+00   1.0e+00  0.60  \n",
      "1   5.7e-15  1.1e+02  1.5e+00  2.72e-01   -1.110441854e-01  7.034336953e-01   7.8e-01  0.71  \n",
      "2   7.8e-15  5.9e+01  6.1e-01  4.30e-01   1.706636871e+00   2.201791829e+00   4.1e-01  0.82  \n",
      "3   9.0e-15  4.9e+01  3.9e-01  1.35e+00   1.897251057e+00   2.312121975e+00   3.4e-01  0.89  \n",
      "4   1.5e-14  3.9e+01  2.2e-01  1.72e+00   2.126284705e+00   2.417837752e+00   2.7e-01  0.97  \n",
      "5   2.6e-14  3.1e+01  1.2e-01  2.19e+00   2.216835225e+00   2.400814882e+00   2.2e-01  1.05  \n",
      "6   6.8e-14  2.7e+01  8.2e-02  2.45e+00   2.222208292e+00   2.348490598e+00   1.9e-01  1.13  \n",
      "7   2.0e-14  2.0e+01  4.3e-02  2.48e+00   2.226632944e+00   2.295339607e+00   1.4e-01  1.21  \n",
      "8   8.5e-14  1.4e+01  2.1e-02  2.36e+00   2.232738796e+00   2.267406255e+00   1.0e-01  1.29  \n",
      "9   1.7e-12  1.2e+01  1.4e-02  1.93e+00   2.260871722e+00   2.285451020e+00   8.1e-02  1.36  \n",
      "10  1.2e-12  8.1e+00  9.2e-03  1.58e+00   2.412323142e+00   2.428958427e+00   5.7e-02  1.46  \n",
      "11  8.5e-13  4.2e+00  5.1e-03  9.01e-01   3.265711443e+00   3.276343514e+00   2.9e-02  1.56  \n",
      "12  6.3e-11  1.6e+00  2.6e-03  -1.16e-01  7.648214893e+00   7.652398057e+00   1.2e-02  1.65  \n",
      "13  4.3e-11  7.5e-01  1.4e-03  -2.89e-01  1.843458840e+01   1.843211564e+01   5.2e-03  1.74  \n",
      "14  3.4e-11  5.4e-01  9.5e-04  -3.25e-01  3.038942203e+01   3.038647275e+01   3.8e-03  1.81  \n",
      "15  3.4e-11  1.1e-01  1.9e-04  -2.95e-01  1.004234645e+02   1.004139241e+02   8.0e-04  1.91  \n",
      "16  8.9e-10  8.0e-02  1.2e-04  2.29e-01   1.323975886e+02   1.323895229e+02   5.6e-04  1.99  \n",
      "17  8.8e-10  7.6e-02  1.2e-04  3.09e-01   1.374915037e+02   1.374838144e+02   5.4e-04  2.07  \n",
      "18  7.2e-10  4.7e-02  6.4e-05  3.40e-01   1.799266431e+02   1.799204711e+02   3.3e-04  2.15  \n",
      "19  7.4e-10  2.4e-02  2.4e-05  5.02e-01   2.390565429e+02   2.390533186e+02   1.7e-04  2.26  \n",
      "20  5.2e-10  2.0e-02  1.7e-05  7.75e-01   2.556866509e+02   2.556840723e+02   1.4e-04  2.34  \n",
      "21  4.2e-10  1.8e-02  1.6e-05  8.50e-01   2.609956152e+02   2.609932406e+02   1.3e-04  2.41  \n",
      "22  3.4e-10  1.7e-02  1.4e-05  8.73e-01   2.650767459e+02   2.650745155e+02   1.2e-04  2.49  \n",
      "23  2.0e-10  1.2e-02  8.0e-06  8.90e-01   2.871266404e+02   2.871251830e+02   8.2e-05  2.57  \n",
      "24  1.0e-09  7.8e-03  4.2e-06  9.86e-01   3.050221389e+02   3.050212330e+02   5.4e-05  2.67  \n",
      "25  1.9e-09  6.2e-03  2.9e-06  1.05e+00   3.124451143e+02   3.124444135e+02   4.3e-05  2.75  \n",
      "26  3.3e-09  4.9e-03  2.0e-06  1.08e+00   3.185543414e+02   3.185538048e+02   3.4e-05  2.82  \n",
      "27  3.9e-09  4.5e-03  1.8e-06  1.10e+00   3.203181841e+02   3.203176921e+02   3.2e-05  2.90  \n",
      "28  4.7e-09  4.2e-03  1.6e-06  1.10e+00   3.219495272e+02   3.219490769e+02   2.9e-05  2.98  \n",
      "29  7.6e-09  2.9e-03  8.8e-07  1.10e+00   3.281933198e+02   3.281930276e+02   2.0e-05  3.08  \n",
      "30  9.8e-09  2.5e-03  7.1e-07  1.12e+00   3.299506929e+02   3.299504433e+02   1.7e-05  3.15  \n",
      "31  1.6e-08  1.7e-03  3.9e-07  1.12e+00   3.336465840e+02   3.336464217e+02   1.2e-05  3.23  \n",
      "32  3.3e-08  9.2e-04  1.5e-07  1.12e+00   3.371379502e+02   3.371378681e+02   6.4e-06  3.32  \n",
      "33  4.3e-08  8.1e-04  1.2e-07  1.12e+00   3.376267808e+02   3.376267097e+02   5.7e-06  3.40  \n",
      "34  7.9e-08  4.3e-04  4.7e-08  1.12e+00   3.392672149e+02   3.392671797e+02   3.0e-06  3.49  \n",
      "35  1.0e-07  3.9e-04  4.0e-08  1.10e+00   3.394598622e+02   3.394598312e+02   2.7e-06  3.57  \n",
      "36  2.1e-07  2.1e-04  1.6e-08  1.10e+00   3.401653432e+02   3.401653271e+02   1.5e-06  3.67  \n",
      "37  2.8e-07  1.9e-04  1.3e-08  1.08e+00   3.402647452e+02   3.402647313e+02   1.3e-06  3.75  \n",
      "38  5.3e-07  9.4e-05  4.5e-09  1.07e+00   3.406179182e+02   3.406179117e+02   6.6e-07  3.84  \n",
      "39  8.8e-07  7.1e-05  3.0e-09  1.06e+00   3.406948163e+02   3.406948114e+02   5.0e-07  3.92  \n",
      "40  1.5e-06  4.6e-05  1.5e-09  1.05e+00   3.407783757e+02   3.407783727e+02   3.2e-07  3.99  \n",
      "41  2.6e-06  3.2e-05  8.6e-10  1.04e+00   3.408234629e+02   3.408234609e+02   2.2e-07  4.07  \n",
      "42  4.2e-06  2.1e-05  4.5e-10  1.03e+00   3.408553557e+02   3.408553545e+02   1.5e-07  4.17  \n",
      "43  6.4e-06  1.5e-05  2.7e-10  1.02e+00   3.408715296e+02   3.408715287e+02   1.0e-07  4.25  \n",
      "44  1.1e-05  9.2e-06  1.3e-10  1.02e+00   3.408863795e+02   3.408863789e+02   6.4e-08  4.33  \n",
      "45  1.9e-05  5.7e-06  6.3e-11  1.01e+00   3.408947674e+02   3.408947671e+02   4.0e-08  4.42  \n",
      "46  2.8e-05  4.2e-06  4.1e-11  1.01e+00   3.408978908e+02   3.408978905e+02   3.0e-08  4.50  \n",
      "47  3.8e-05  3.4e-06  3.0e-11  1.01e+00   3.408995292e+02   3.408995290e+02   2.4e-08  4.57  \n",
      "48  7.5e-05  1.3e-06  6.8e-12  1.01e+00   3.409037585e+02   3.409037585e+02   9.1e-09  4.67  \n",
      "49  1.3e-04  1.0e-06  4.8e-12  1.01e+00   3.409041966e+02   3.409041966e+02   7.3e-09  4.74  \n",
      "50  9.7e-05  6.6e-07  2.5e-12  1.01e+00   3.409047767e+02   3.409047767e+02   4.7e-09  4.95  \n",
      "51  2.5e-04  5.2e-07  1.7e-12  9.97e-01   3.409050106e+02   3.409050106e+02   3.6e-09  5.02  \n",
      "52  5.9e-04  3.3e-07  8.5e-13  1.00e+00   3.409052647e+02   3.409052646e+02   2.3e-09  5.18  \n",
      "Optimizer terminated. Time: 5.30    \n",
      "\n",
      "\n",
      "Interior-point solution summary\n",
      "  Problem status  : PRIMAL_AND_DUAL_FEASIBLE\n",
      "  Solution status : OPTIMAL\n",
      "  Primal.  obj: 3.4090526466e+02    nrm: 9e+02    Viol.  con: 2e-13    var: 8e-09    cones: 0e+00  \n",
      "  Dual.    obj: 3.4090526464e+02    nrm: 3e+02    Viol.  con: 0e+00    var: 3e-06    cones: 0e+00  \n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 09 04:52:41 PM: Problem status: optimal\n",
      "(CVXPY) May 09 04:52:41 PM: Optimal value: 3.409e+02\n",
      "(CVXPY) May 09 04:52:41 PM: Compilation took 2.898e+01 seconds\n",
      "(CVXPY) May 09 04:52:41 PM: Solver (including time spent in interface) took 5.693e+00 seconds\n",
      "Optimal value: 340.9051895157283\n",
      "Variable var45: value [ 9.46443612e-01  1.18264430e-03  7.36101454e-02 ... -5.10961488e-09\n",
      " -4.72867421e-09 -5.05000362e-09]\n"
     ]
    }
   ],
   "source": [
    "## We run the optimiser to get the transports between water masses and the T,S mixed and T,S adjustment\n",
    "result = MTM.optimise(tracers, volumes, constraints, weights)\n",
    "\n",
    "g_ij = result['g_ij'] ## An [N x N] matrix of transports between WMs\n",
    "Mixing = result['Mixing'] ## An [M x N] matrix of dtracer mixing for each WM\n",
    "Adjustment = result['Adjustment'] ## An [M x N] matrix of dtracer adjustment for each WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Break down the Mixing and Adjustment matrices into their constituent tracers\n",
    "dT_mixing = Mixing[1,:]\n",
    "dS_mixing = Mixing[0,:]\n",
    "dS_adj = Adjustment[0,:]\n",
    "dT_adj = Adjustment[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## E) Save Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dT_mixing = xr.DataArray(data = dT_mixing, dims = [\"WM_number\"],\n",
    "                           coords=dict(WM_number = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Temperature Mixing\", units=\"\\Delta K\", variable_id=\"EN4 Tmix\"))\n",
    "da_dS_mixing = xr.DataArray(data = dS_mixing, dims = [\"WM_number\"],\n",
    "                           coords=dict(WM_number = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Salinity Mixing\", units=\"\\Delta g/kg\", variable_id=\"EN4 Smix\"))\n",
    "da_dT_adjustment = xr.DataArray(data = dT_adj, dims = [\"WM_number\"],\n",
    "                           coords=dict(WM_number = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Temperature Adjustment\", units=\"\\Delta K\", variable_id=\"EN4 Tadj\"))\n",
    "da_dS_adjustment = xr.DataArray(data = dS_adj, dims = [\"WM_number\"],\n",
    "                           coords=dict(WM_number = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Salinity Adjustment\", units=\"\\Delta g/kg\", variable_id=\"EN4 Sadj\"))\n",
    "da_gij = xr.DataArray(data = g_ij*volnorming, dims = [\"WM_initial\", \"WM_final\"],\n",
    "                           coords=dict(WM_initial = np.arange(0,N), WM_final = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Volume transport\", units=\"m^3\", variable_id=\"EN4 Gij\"))\n",
    "\n",
    "## Create xarray DataSet that will hold all these DataArrays\n",
    "ds_BSP = xr.Dataset()\n",
    "ds_BSP['dT_mixing'] = da_dT_mixing\n",
    "ds_BSP['dS_mixing'] = da_dS_mixing\n",
    "ds_BSP['dT_adjustment'] = da_dT_adjustment\n",
    "ds_BSP['dS_adjustment'] = da_dS_adjustment\n",
    "ds_BSP['gij'] = da_gij\n",
    "\n",
    "ds_BSP.to_netcdf('Optimal_result_EN4.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN4_3D_data = xr.open_mfdataset('~/UNSW_Work/EN4_Data/EN_data/EN4_CT*.nc')\n",
    "EN4_3D_mask = xr.open_mfdataset('~/UNSW_Work/Min_Transform_Method/mask*')\n",
    "# partitions_bins = EN4_data.Partitions_hist.isel(Time=slice(0,12)).mean('Time').isel(Basin=0).values\n",
    "# EN4_3D_mask_numpy = EN4_3D_mask.__xarray_dataarray_variable__.values\n",
    "# EN4_3D_SA_mean = EN4_3D_data.Abs_Sal.isel(time=slice(0,12)).mean('time')\n",
    "# EN4_3D_CT_mean = EN4_3D_data.Cons_Temp.isel(time=slice(0,12)).mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_Av_adj_2D = T_Av_adj.reshape(Basins.size, 128)\n",
    "S_Av_adj_2D = S_Av_adj.reshape(Basins.size, 128)\n",
    "T_Av_mix_2D = T_Av_mix.reshape(Basins.size, 128)\n",
    "S_Av_mix_2D = S_Av_mix.reshape(Basins.size, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827509ec621c468f94e83c3b7c187593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'EN4_3D_SA_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w5/g46qs36s59xcqy7pwf4841q80000gq/T/ipykernel_57003/2580678396.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         masked_T_adj_grid = xr.where((EN4_3D_SA_mean>partitions_bins[j,0])&\\\n\u001b[0m\u001b[1;32m      6\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0mEN4_3D_SA_mean\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mpartitions_bins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0mEN4_3D_CT_mean\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mpartitions_bins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EN4_3D_SA_mean' is not defined"
     ]
    }
   ],
   "source": [
    "masked_T_adj_grid_bsum =0\n",
    "masked_T_adj_grid_sum = 0\n",
    "for j in tqdm(range(128)):\n",
    "    for k in range(Basins.size):\n",
    "        masked_T_adj_grid = xr.where((EN4_3D_SA_mean>partitions_bins[j,0])&\\\n",
    "                                (EN4_3D_SA_mean<partitions_bins[j,1])&\\\n",
    "                                (EN4_3D_CT_mean>partitions_bins[j,2])&\\\n",
    "                                (EN4_3D_CT_mean<partitions_bins[j,3]), \\\n",
    "                                T_Av_adj_2D[k,j]*EN4_3D_mask_numpy[k,:,:,:], 0)\n",
    "        masked_T_adj_grid_bsum = masked_T_adj_grid_bsum+masked_T_adj_grid\n",
    "    masked_T_adj_grid_sum = masked_T_adj_grid_bsum+masked_T_adj_grid_sum\n",
    "\n",
    "# masked_S_adj_grid_bsum =0\n",
    "# masked_S_adj_grid_sum = 0\n",
    "# for j in tqdm(range(128)):\n",
    "#     for k in range(Basins.size):\n",
    "#         masked_S_adj_grid = xr.where((EN4_3D_SA_mean>partitions_bins[j,0])&\\\n",
    "#                                 (EN4_3D_SA_mean<partitions_bins[j,1])&\\\n",
    "#                                 (EN4_3D_CT_mean>partitions_bins[j,2])&\\\n",
    "#                                 (EN4_3D_CT_mean<partitions_bins[j,3]), \\\n",
    "#                                 S_Av_adj_2D[k,j]*EN4_3D_mask_numpy[k,:,:,:], 0)\n",
    "#         masked_S_adj_grid_bsum = masked_S_adj_grid_bsum+masked_S_adj_grid\n",
    "#     masked_S_adj_grid_sum = masked_S_adj_grid_bsum+masked_S_adj_grid_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf57312b857c40d0af2a5cc80d942a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'EN4_3D_SA_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w5/g46qs36s59xcqy7pwf4841q80000gq/T/ipykernel_57003/966425238.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         masked_T_mix_grid = xr.where((EN4_3D_SA_mean>partitions_bins[j,0])&\\\n\u001b[0m\u001b[1;32m      6\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0mEN4_3D_SA_mean\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mpartitions_bins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0mEN4_3D_CT_mean\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mpartitions_bins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EN4_3D_SA_mean' is not defined"
     ]
    }
   ],
   "source": [
    "masked_T_mix_grid_bsum =0\n",
    "masked_T_mix_grid_sum = 0\n",
    "for j in tqdm(range(128)):\n",
    "    for k in range(Basins.size):\n",
    "        masked_T_mix_grid = xr.where((EN4_3D_SA_mean>partitions_bins[j,0])&\\\n",
    "                                (EN4_3D_SA_mean<partitions_bins[j,1])&\\\n",
    "                                (EN4_3D_CT_mean>partitions_bins[j,2])&\\\n",
    "                                (EN4_3D_CT_mean<partitions_bins[j,3]), \\\n",
    "                                T_Av_mix_2D[k,j]*EN4_3D_mask_numpy[k,:,:,:], 0)\n",
    "        masked_T_mix_grid_bsum = masked_T_mix_grid_bsum+masked_T_mix_grid\n",
    "    masked_T_mix_grid_sum = masked_T_mix_grid_bsum+masked_T_mix_grid_sum\n",
    "# masked_T_mix_grid_sum = masked_T_mix_grid_sum/(T_Av_mix.size)\n",
    "\n",
    "# masked_S_mix_grid_bsum =0\n",
    "# masked_S_mix_grid_sum = 0\n",
    "# for j in tqdm(range(128)):\n",
    "#     for k in range(Basins.size):\n",
    "#         masked_S_mix_grid = xr.where((EN4_3D_SA_mean>partitions_bins[j,0])&\\\n",
    "#                                 (EN4_3D_SA_mean<partitions_bins[j,1])&\\\n",
    "#                                 (EN4_3D_CT_mean>partitions_bins[j,2])&\\\n",
    "#                                 (EN4_3D_CT_mean<partitions_bins[j,3]), \\\n",
    "#                                 S_Av_mix_2D[k,j]*EN4_3D_mask_numpy[k,:,:,:], 0)\n",
    "#         masked_S_mix_grid_bsum = masked_S_mix_grid_bsum+masked_S_mix_grid\n",
    "#     masked_S_mix_grid_sum = masked_S_mix_grid_bsum+masked_S_mix_grid_sum\n",
    "# masked_S_mix_grid_sum = masked_S_mix_grid_sum/(S_Av_mix.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_T_adj_grid_DA = ((masked_T_adj_grid_sum*EN4_3D_data.dVol.isel(time=0)).sum('depth')/(EN4_3D_data.dVol.isel(time=0)).sum('depth')).values\n",
    "# masked_S_adj_grid_DA = ((masked_S_adj_grid_sum*EN4_3D_data.dVol.isel(time=0)).sum('depth')/(EN4_3D_data.dVol.isel(time=0)).sum('depth')).values\n",
    "masked_T_mix_grid_DA = (((masked_T_mix_grid_sum*EN4_3D_data.dVol.isel(time=0)).sum('depth')*EN4_3D_data.dVol.isel(time=0,depth=0))/(EN4_3D_data.dVol.isel(time=0)).sum('depth')).values\n",
    "# masked_S_mix_grid_DA = ((masked_S_mix_grid_sum*EN4_3D_data.dVol.isel(time=0)).sum('depth')/(EN4_3D_data.dVol.isel(time=0)).sum('depth')).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(masked_T_adj_grid_DA/44, vmin=-1, vmax=1, cmap=plt.cm.bwr)\n",
    "plt.gca().add_patch(patches.Rectangle((0,0), 360, 180, color='black',zorder=0))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# plt.pcolormesh(masked_S_adj_grid_DA/44*10, vmin=-0.001, vmax=0.001, cmap=plt.cm.bwr)\n",
    "# plt.gca().add_patch(patches.Rectangle((0,0), 360, 180, color='black',zorder=0))\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "plt.pcolormesh(masked_T_mix_grid_DA/44, vmin=-1, vmax=1, cmap=plt.cm.bwr)\n",
    "plt.gca().add_patch(patches.Rectangle((0,0), 360, 180, color='black',zorder=0))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.pcolormesh((masked_T_mix_grid_DA+masked_T_adj_grid_DA)/44, vmin=-1, vmax=1, cmap=plt.cm.bwr)\n",
    "plt.gca().add_patch(patches.Rectangle((0,0), 360, 180, color='black',zorder=0))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum((masked_T_mix_grid_DA+masked_T_adj_grid_DA))\n",
    "# plt.hist(masked_T_adj_grid_DA.flatten()/44, bins = np.linspace(-1,1,150))\n",
    "# plt.hist(masked_T_mix_grid_DA.flatten()/44, bins = np.linspace(-1,1,150))\n",
    "# plt.hist((masked_T_adj_grid_DA+masked_T_mix_grid_DA).flatten()/44, bins = np.linspace(-1,1,150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Eulerian change in temperature (just a simple difference)\n",
    "dT_eul=np.nanmean(CTlate-CTearly,axis=-1)\n",
    "# Compute depth integrated heat content (units: W/m^2)\n",
    "dH_mix = Cp*rho*np.nansum(dT_mix*vol,axis=-1)/(darea*dyrs*yr2sec)\n",
    "dH_eul = Cp*rho*np.nansum(dT_eul*vol,axis=-1)/(darea*dyrs*yr2sec)\n",
    "dH_adj = Cp*rho*np.nansum(dT_adj*vol,axis=-1)/(darea*dyrs*yr2sec)\n",
    "dH_eul[dH_eul==0]=np.nan\n",
    "dH_mix[dH_mix==0]=np.nan\n",
    "dH_adj[dH_adj==0]=np.nan\n",
    "dH_redist = dH_eul-dH_mix-dH_adj\n",
    "\n",
    "# Compare Mixing, Redistribution and Adjustment fresh water change\n",
    "# Compute Eulerian change in temperature (just a simple difference)\n",
    "dS_eul=np.nanmean(SAlate-SAearly,axis=-1)\n",
    "# Compute implied fresh water content change (units: mm/yr)\n",
    "dW_mix = (-1/S0)*np.nansum(dS_mix*vol,axis=-1)/(darea*dyrs)*1000\n",
    "dW_eul = (-1/S0)*np.nansum(dS_eul*vol,axis=-1)/(darea*dyrs)*1000\n",
    "dW_adj = (-1/S0)*np.nansum(dS_adj*vol,axis=-1)/(darea*dyrs)*1000\n",
    "dW_eul[dW_eul==0]=np.nan\n",
    "dW_mix[dW_mix==0]=np.nan\n",
    "dW_adj[dW_adj==0]=np.nan\n",
    "dW_redist = dW_eul - dW_mix - dW_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3, figsize=(40*0.5,17.5*0.5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .15, wspace=0.15)\n",
    "axs = axs.ravel() \n",
    "cax1 = fig.add_axes([0.925, 0.55, 0.02, 0.34])\n",
    "cax2 = fig.add_axes([0.925, 0.12, 0.02, 0.34])\n",
    "\n",
    "axs[0].add_patch(patches.Rectangle((np.min(lon), np.min(lat)), lon.size, lat.size, color='black',zorder=0))\n",
    "axs[1].add_patch(patches.Rectangle((np.min(lon), np.min(lat)), lon.size, lat.size, color='black',zorder=0))\n",
    "axs[2].add_patch(patches.Rectangle((np.min(lon), np.min(lat)), lon.size, lat.size, color='black',zorder=0))\n",
    "axs[3].add_patch(patches.Rectangle((np.min(lon), np.min(lat)), lon.size, lat.size, color='black',zorder=0))\n",
    "axs[4].add_patch(patches.Rectangle((np.min(lon), np.min(lat)), lon.size, lat.size, color='black',zorder=0))\n",
    "axs[5].add_patch(patches.Rectangle((np.min(lon), np.min(lat)), lon.size, lat.size, color='black',zorder=0))\n",
    "\n",
    "axs[0].pcolormesh(lon,lat,np.moveaxis(dH_mix, -1,0), vmin=-150,vmax=150, zorder=1,  cmap='bwr')\n",
    "axs[1].pcolormesh(lon,lat,np.moveaxis(dH_redist, -1,0), vmin=-150, vmax=150, zorder=1, cmap='bwr')\n",
    "axs[2].pcolormesh(lon,lat,np.moveaxis(dH_adj, -1,0), vmin=-150, vmax=150, zorder=1, cmap='bwr')\n",
    "axs[3].pcolormesh(lon,lat,np.moveaxis(dW_mix, -1,0), vmin=-5000,vmax=5000, zorder=1,  cmap='bwr')\n",
    "axs[4].pcolormesh(lon,lat,np.moveaxis(dW_redist, -1,0), vmin=-5000, vmax=5000, zorder=1, cmap='bwr')\n",
    "axs[5].pcolormesh(lon,lat,np.moveaxis(dW_adj, -1,0), vmin=-5000, vmax=5000, zorder=1, cmap='bwr')\n",
    "\n",
    "axs[0].grid(True, zorder=2)\n",
    "axs[1].grid(True, zorder=2)\n",
    "axs[2].grid(True, zorder=2)\n",
    "axs[3].grid(True, zorder=2)\n",
    "axs[4].grid(True, zorder=2)\n",
    "axs[5].grid(True, zorder=2)\n",
    "\n",
    "axs[0].set_title('Mixing')\n",
    "axs[1].set_title('Adiabatic Redistribution')\n",
    "axs[2].set_title(r'Adjustment')\n",
    "\n",
    "axs[3].set_xlabel('Longitude')\n",
    "axs[4].set_xlabel('Longitude')\n",
    "axs[5].set_xlabel('Longitude')\n",
    "\n",
    "axs[0].set_ylabel('Latitude')\n",
    "axs[3].set_ylabel('Latitude')\n",
    "\n",
    "axs[0].set_xlim(np.min(lon), np.max(lon))\n",
    "axs[1].set_xlim(np.min(lon), np.max(lon))\n",
    "axs[2].set_xlim(np.min(lon), np.max(lon))\n",
    "axs[3].set_xlim(np.min(lon), np.max(lon))\n",
    "axs[4].set_xlim(np.min(lon), np.max(lon))\n",
    "axs[5].set_xlim(np.min(lon), np.max(lon))\n",
    "\n",
    "axs[0].set_ylim(np.min(lat), np.max(lat))\n",
    "axs[1].set_ylim(np.min(lat), np.max(lat))\n",
    "axs[2].set_ylim(np.min(lat), np.max(lat))\n",
    "axs[3].set_ylim(np.min(lat), np.max(lat))\n",
    "axs[4].set_ylim(np.min(lat), np.max(lat))\n",
    "axs[5].set_ylim(np.min(lat), np.max(lat))\n",
    "\n",
    "m = plt.cm.ScalarMappable(cmap='bwr')\n",
    "m.set_clim(-5,5)\n",
    "cbar2 = fig.colorbar(m, cax=cax2, orientation='vertical')\n",
    "cbar2.set_label('$m/yr$') \n",
    "\n",
    "m = plt.cm.ScalarMappable(cmap='bwr')\n",
    "m.set_clim(-150,150)\n",
    "cbar1 = fig.colorbar(m, cax=cax1, orientation='vertical')\n",
    "cbar1.set_label('$W/m^2$') \n",
    "\n",
    "plt.savefig('Minimisation_remapped_128_unmixing.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(30*0.5,10*0.5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .15, wspace=0.15)\n",
    "axs = axs.ravel() \n",
    "\n",
    "ind = np.arange(4)\n",
    "width=1/6\n",
    "axs[0].barh(ind+width/2*3, \\\n",
    "        [dH_mix_Atl_avg , dH_adj_Atl_avg , dH_redist_Atl_avg, dH_redist_Atl_avg+dH_mix_Atl_avg+dH_adj_Atl_avg], width, color='skyblue', label='Atlantic')\n",
    "axs[0].barh(ind+width/2, \\\n",
    "        [dH_mix_SO_avg, dH_adj_SO_avg,  dH_redist_SO_avg, dH_redist_SO_avg+dH_mix_SO_avg+dH_adj_SO_avg], width, color='orange', label='Southern')\n",
    "axs[0].barh(ind-width/2, \\\n",
    "        [dH_mix_Pac_avg, dH_adj_Pac_avg,  dH_redist_Pac_avg, dH_redist_Pac_avg+dH_mix_Pac_avg+dH_adj_Pac_avg], width, color='purple', label='Pacific')\n",
    "axs[0].barh(ind-3*width/2, \\\n",
    "        [dH_mix_Ind_avg,  dH_adj_Ind_avg, dH_redist_Ind_avg, \\\n",
    "         dH_redist_Ind_avg+dH_mix_Ind_avg+dH_adj_Ind_avg], width, color='black', label='Indian')\n",
    "\n",
    "axs[1].barh(ind+width/2*3, \\\n",
    "        [dW_mix_Atl_avg , dW_adj_Atl_avg , dW_redist_Atl_avg, dW_redist_Atl_avg+dW_mix_Atl_avg+dW_adj_Atl_avg], width, color='skyblue', label='Atlantic')\n",
    "axs[1].barh(ind+width/2, \\\n",
    "        [dW_mix_SO_avg, dW_adj_SO_avg,  dW_redist_SO_avg, dW_redist_SO_avg+dW_mix_SO_avg+dW_adj_SO_avg], width, color='orange', label='Southern')\n",
    "axs[1].barh(ind-width/2, \\\n",
    "        [dW_mix_Pac_avg, dW_adj_Pac_avg,  dW_redist_Pac_avg, dW_redist_Pac_avg+dW_mix_Pac_avg+dW_adj_Pac_avg], width, color='purple', label='Pacific')\n",
    "axs[1].barh(ind-3*width/2, \\\n",
    "        [dW_mix_Ind_avg,  dW_adj_Ind_avg, dW_redist_Ind_avg, \\\n",
    "         dW_redist_Ind_avg+dW_mix_Ind_avg+dW_adj_Ind_avg], width, color='black', label='Indian')\n",
    "\n",
    "\n",
    "axs[0].grid()\n",
    "# axs[0].set_ylabel('Basin', labelpad=25)\n",
    "axs[0].set_xlabel('Mean Heat Content Change [Wm$^{-2}$]')\n",
    "axs[0].set_yticks([0,1,2,3])\n",
    "axs[0].set_yticklabels(['Mixing', 'Adjustment', 'Redistribution', 'Total'])\n",
    "axs[0].set_ylim(ind[0]-width*2, ind[-1]+width*2)\n",
    "axs[0].legend(ncol=4, bbox_to_anchor=(1.05,-0.3), loc='center')\n",
    "# axs[0].set_xlim(-3.1,3.1)\n",
    "\n",
    "axs[1].grid()\n",
    "axs[1].set_xlabel('Mean Freshwater Change [myr$^{-1}$]')\n",
    "axs[1].set_yticks([0,1,2,3])\n",
    "axs[1].set_yticklabels(['','','',''])\n",
    "axs[1].set_ylim(ind[0]-width*2, ind[-1]+width*2)\n",
    "# axs[1].set_xlim(-0.08,0.08)\n",
    "\n",
    "plt.savefig('Minimisation_basin_bars_global.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
