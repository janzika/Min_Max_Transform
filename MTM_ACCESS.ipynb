{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Minimum Transformation Method\n",
    "## <center>An inverse model for inferring surface fluxes and mixing from gridded hydrographic TS data, <br> by Taimoor Sohail and Jan D. Zika\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <center>We use an optimal transport method, minimzing a cost function which respects the volume and mass conservation, and the fundamental physics of mixing in TS space. <br>See also: Jan D Zika et al. (2021) [www.doi.org/10.1175/JCLI-D-20-0355.1 ] for a simpler version of this model which optimizes ocean circulation only.\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __The code is laid out as follows:__\n",
    "#### A) Pre-processing\n",
    "i) Load necessary modules for computation \\\n",
    "ii) Define key parameters\n",
    "#### B) Load Data\n",
    "#### C) Define constraints\n",
    "i) Define Connectivity \\\n",
    "ii) Define weights\n",
    "#### D) Run optimisation\n",
    "#### E) Save Output\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Load necessary modules for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Module to run the minimisation\n",
    "from WM_Methods import MTM\n",
    "## Module to track runtime of cells and loops\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "## Suppress warnings related to division by zero\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "## Module to load files and handle array computations\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "## Modules to plot outputs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "# Specify font properties for plots\n",
    "# from matplotlib import rc\n",
    "# font = {'family' : 'DejaVu Sans',\n",
    "#         'weight' : 'normal',\n",
    "#         'size'   : 16}\n",
    "\n",
    "# rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Define key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 6000]\n"
     ]
    }
   ],
   "source": [
    "# Thermal expansion, haline contraction and true scale factor\n",
    "alph = 1.7657*10**-4\n",
    "bet = 7.5544*10**-4\n",
    "\n",
    "volnorming = 10**15 #normalising coeffcients\n",
    "areanorming = 10**12 #normalising coeffcients\n",
    "ST_scale=bet/alph\n",
    "\n",
    "# Establish basic constants \n",
    "yr2sec = 365.25*24*60*60\n",
    "Cp=4000\n",
    "rho=1024\n",
    "S0=35\n",
    "\n",
    "# If Surface fluxes are available\n",
    "SF = True\n",
    "# To run the optimisation twice \n",
    "Opt_twice = False\n",
    "\n",
    "# Range of years of which 'early' and 'late' are defined\n",
    "\n",
    "if SF:\n",
    "    ## ERA5 begins in 1979 so we have to change our \"early\" and \"late\" periods\n",
    "    dyrs = 500\n",
    "    init_early = 0\n",
    "    init_late = 0\n",
    "    Early_period = (np.array([init_early,init_early+dyrs]) - init_early)*12\n",
    "    Late_period = (np.array([init_late,init_late+dyrs]) - init_early)*12\n",
    "    range_yrs = init_late-init_early+1\n",
    "else:\n",
    "    dyrs = 9\n",
    "    init_early = 1979\n",
    "    init_late = 2006\n",
    "    Early_period = (np.array([init_early,init_early+dyrs]) - init_early)*12\n",
    "    Late_period = (np.array([init_late,init_late+dyrs]) - init_early)*12\n",
    "    range_yrs = init_late-init_early+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## B) Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The data is presented as monthly T-S observations from EN4, from January 1970 to December 2014. The observations have already been binned via Binary Space Partitioning according to a specific criterion. Folowing Sohail et al. (TBD) the BSP partitioning occurs in an xyxyxyx order, shown to minimize variability in the temperature and salinity signals. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 36.5 ms, total: 1.25 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if SF:\n",
    "    ACCESS_BSP_data = xr.open_mfdataset('BSP_processed/BSP_ACCESS*.nc')\n",
    "    \n",
    "    ## Early Period\n",
    "    Part_early = ACCESS_BSP_data.Partitions.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "    SA_early =  ACCESS_BSP_data.S_mean.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "    CT_early = ACCESS_BSP_data.T_mean.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "    V_early = ACCESS_BSP_data.V_sum.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "    A_early = ACCESS_BSP_data.A_sum.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "\n",
    "    ## Late Period\n",
    "    Part_late = ACCESS_BSP_data.Partitions.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "    SA_late =  ACCESS_BSP_data.S_mean.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "    CT_late = ACCESS_BSP_data.T_mean.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "    V_late = ACCESS_BSP_data.V_sum.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "    A_late = ACCESS_BSP_data.A_sum.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "\n",
    "    Basins = ACCESS_BSP_data.Basin.values\n",
    "else:\n",
    "    EN4_BSP_data = xr.open_mfdataset('BSP_processed/BSP_EN4_TS_*.nc')\n",
    "\n",
    "    ## Early Period\n",
    "    Part_early = EN4_BSP_data.Partitions.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "    SA_early =  EN4_BSP_data.S_mean.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "    CT_early = EN4_BSP_data.T_mean.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "    V_early = EN4_BSP_data.V_sum.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "    A_early = EN4_BSP_data.A_sum.isel(Time=slice(Early_period[0],Early_period[1])).mean('Time')\n",
    "\n",
    "\n",
    "    ## Late Period\n",
    "    Part_late = EN4_BSP_data.Partitions.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "    SA_late =  EN4_BSP_data.S_mean.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "    CT_late = EN4_BSP_data.T_mean.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "    V_late = EN4_BSP_data.V_sum.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "    A_late = EN4_BSP_data.A_sum.isel(Time=slice(Late_period[0],Late_period[1])).mean('Time')\n",
    "\n",
    "    Basins = EN4_BSP_data.Basin.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load ERA5 data here, if provided\n",
    "if SF:\n",
    "    time = ACCESS_BSP_data.Time.values\n",
    "    ## Calculate the time-mean hfds and wfo\n",
    "    dhfds = ACCESS_BSP_data.hfds_sum.mean('Time')*(1/(24*3600)) # units: W\n",
    "    dwfo = ACCESS_BSP_data.wfo_sum.mean('Time') # units: kg/s\n",
    "\n",
    "    ## Convert dflux to equivalent T or S change\n",
    "    dT_hfds = dhfds/(Cp*rho*V_early)*yr2sec # units: C/yr\n",
    "    dS_wfo = -dwfo*S0/(rho*V_early)*yr2sec # units: g/kg/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten the early and late variables to a 1D array\n",
    "Vol_1 = V_early.values.flatten()\n",
    "Vol_2 = V_late.values.flatten()\n",
    "S_1 = SA_early.values.flatten()-S0 # Remove reference salinity S0\n",
    "S_2 = SA_late.values.flatten()-S0 # Remove reference salinity S0\n",
    "T_1 = CT_early.values.flatten()\n",
    "T_2 = CT_late.values.flatten()\n",
    "A_1 = A_early.values.flatten()\n",
    "A_2 = A_late.values.flatten()\n",
    "\n",
    "# Do the same for basin index\n",
    "Basin_1 = np.zeros_like(V_early)\n",
    "Basin_2 = np.zeros_like(V_early)\n",
    "Basin_names = []\n",
    "for i in range(np.array(Basins).size):\n",
    "    Basin_1[i,:] = i\n",
    "    Basin_2[i,:] = i\n",
    "    for j in range(V_early.shape[-1]):\n",
    "        #... and for basin name\n",
    "        Basin_names.append(Basins[i])\n",
    "\n",
    "Basin_1_inds = Basin_1.flatten()\n",
    "Basin_2_inds = Basin_2.flatten()\n",
    "\n",
    "#... and for the edges of the BSP bins\n",
    "## Here we calculate the mean TS edges averaged over both early and late times\n",
    "S_start = (0.5*(Part_early.values[:,:,0]+Part_late.values[:,:,0])).flatten()-S0 # Remove reference salinity S0\n",
    "S_end = (0.5*(Part_early.values[:,:,1]+Part_late.values[:,:,1])).flatten()-S0 # Remove reference salinity S0\n",
    "T_start = (0.5*(Part_early.values[:,:,2]+Part_late.values[:,:,2])).flatten()\n",
    "T_end = (0.5*(Part_early.values[:,:,3]+Part_late.values[:,:,3])).flatten()\n",
    "\n",
    "# Any NaNs are zeroed out\n",
    "S_1[np.isnan(S_1)] = 0\n",
    "S_2[np.isnan(S_2)] = 0\n",
    "T_1[np.isnan(T_1)] = 0\n",
    "T_2[np.isnan(T_2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IF SURFACE FLUXES ARE PROVIDED -- add here ##\n",
    "if SF:\n",
    "    S_pre = SA_early.values.flatten()-S0\n",
    "    S_1 = SA_early.values.flatten()-S0+dS_wfo.values.flatten()\n",
    "    T_pre = CT_early.values.flatten()\n",
    "    T_1 = CT_early.values.flatten()+dT_hfds.values.flatten()\n",
    "\n",
    "    S_1[np.isnan(S_1)] = 0\n",
    "    T_1[np.isnan(T_1)] = 0\n",
    "    S_1[~np.isfinite(S_1)] = 0\n",
    "    T_1[~np.isfinite(T_1)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we create the tracers and volumes matrices, which will be fed into the MTM function\n",
    "\n",
    "volumes = np.stack((Vol_1, Vol_2), axis=0)/volnorming # Shape: [2 x N]\n",
    "\n",
    "salinities = np.stack((S_1, S_2), axis=0)\n",
    "temps = np.stack((T_1, T_2), axis=0)\n",
    "\n",
    "tracers = np.stack((salinities, temps),axis=1) # Shape: [2 x M x N], where M = 2 for just T and S, and M>2 for T,S+other tracers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of bins = 1152\n"
     ]
    }
   ],
   "source": [
    "print('Total number of bins =', int(Vol_1.shape[0]))\n",
    "N = int(Vol_1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## C) Define Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Define Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must define whether a BSP bin is allowed to transport volume to another BSP bin. In the simplest case, all bins are allowed to transport to one another - but this yields nonphysical transport across vast distances and TS bounds.\n",
    "To improve on this, two connectivity constraints are used: \n",
    "1) Are the basins adjacent? This is defined via the connectivity array, below\n",
    "2) If YES, do the BSP bins have overlapping (or the same) TS boundaries?\\\n",
    "If yes, the bins are connected. If no, they are not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6823960000000002\n"
     ]
    }
   ],
   "source": [
    "# Array defining the connection between the 9 basins;\n",
    "# 1 = connected, 0 = disconnected\n",
    "connectivity_array = np.zeros((Basins.size,Basins.size))\n",
    "\n",
    "connectivity_array[0,:] = [1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "connectivity_array[1,:] = [1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "connectivity_array[2,:] = [0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "connectivity_array[3,:] = [0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
    "connectivity_array[4,:] = [0, 0, 0, 0, 1, 0, 1, 0, 1]\n",
    "connectivity_array[5,:] = [0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
    "connectivity_array[6,:] = [0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
    "connectivity_array[7,:] = [0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
    "connectivity_array[8,:] = [0, 0, 0, 1, 1, 1, 0, 0, 1]\n",
    "\n",
    "# Array defining the transport between the 9 basins;\n",
    "# +/-1 = connected (North = +, East = +), 0 = no constraint\n",
    "transport_array = np.zeros((Basins.size,Basins.size))\n",
    "transport_array2 = np.zeros((Basins.size,Basins.size))\n",
    "\n",
    "transport_array[4,:] = [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "transport_array[6,:] = [0, 0, 0, 0, -1, 0, 0, 0, 0]\n",
    "\n",
    "transport_array2[0,:] = [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "print(170/volnorming*(0.5*yr2sec*10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3aa7cef64d4ecf98a10c3c387dae27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define whether a bin is connected to every other bin\n",
    "# The two constraints used are: are the basins adjacent? \n",
    "# If yes, are the bin indices the same? \n",
    "# If yes, the bins are connected; if no, they are not connected. \n",
    "connected = np.zeros((Vol_1.size, Vol_1.size))\n",
    "trans_big = np.zeros((Vol_1.size, Vol_1.size))\n",
    "trans_big2 = np.zeros((Vol_1.size, Vol_1.size))\n",
    "\n",
    "for i in tqdm(range(Vol_1.size)):\n",
    "    for j in range(Vol_2.size):\n",
    "        trans_big[i,j] = transport_array[int(Basin_1_inds[i]), int(Basin_2_inds[j])]\n",
    "        trans_big2[i,j] = transport_array2[int(Basin_1_inds[i]), int(Basin_2_inds[j])]\n",
    "        if connectivity_array[int(Basin_1_inds[i]), int(Basin_2_inds[j])]>0:\n",
    "                if Basin_names[i] == Basin_names[j]:\n",
    "                    connected[i,j] = connectivity_array[int(Basin_1_inds[i]), int(Basin_2_inds[j])]\n",
    "                elif S_start[i]==S_start[j] and T_start[i]==T_start[j]:\n",
    "                    connected[i,j] = connectivity_array[int(Basin_1_inds[i]), int(Basin_2_inds[j])]\n",
    "\n",
    "constraints = connected # Shape: An [N x N] matrix\n",
    "\n",
    "transport = trans_big\n",
    "transport2 = trans_big2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Define Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We create a weight matrix\n",
    "# Note that the code is very sensitive to the weights we input, and may break (TO BE DEVELOPED)\n",
    "offset = 10**10 # To prevent divide by zero errors\n",
    "# Mask where 1/A = inf\n",
    "# area_weight = np.ones_like(A_2)\n",
    "area_weight = np.log10(areanorming)/(np.log10(A_2))\n",
    "area_weight[area_weight==0] = 10\n",
    "# print(ST_scale)\n",
    "weights = np.stack((ST_scale*area_weight,area_weight), axis=0) # Shape: An [M x N] matrix\n",
    "# weights = np.ones_like(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## D) Run Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                    v1.1.13                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jun 23 10:38:34 AM: Your problem has 149760 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Jun 23 10:38:37 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jun 23 10:38:37 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jun 23 10:38:37 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 23 10:38:37 AM: Compiling problem (target solver=MOSEK).\n",
      "(CVXPY) Jun 23 10:38:37 AM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> MOSEK\n",
      "(CVXPY) Jun 23 10:38:37 AM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Jun 23 10:38:37 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jun 23 10:38:37 AM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Jun 23 10:39:05 AM: Applying reduction MOSEK\n",
      "(CVXPY) Jun 23 10:39:05 AM: Finished problem compilation (took 2.808e+01 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 23 10:39:05 AM: Invoking solver MOSEK  to obtain a solution.\n",
      "\n",
      "\n",
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : max             \n",
      "  Type                   : CONIC (conic optimization problem)\n",
      "  Constraints            : 149761          \n",
      "  Cones                  : 1               \n",
      "  Scalar variables       : 154371          \n",
      "  Matrix variables       : 0               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer started.\n",
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : max             \n",
      "  Type                   : CONIC (conic optimization problem)\n",
      "  Constraints            : 149761          \n",
      "  Cones                  : 1               \n",
      "  Scalar variables       : 154371          \n",
      "  Matrix variables       : 0               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer  - threads                : 12              \n",
      "Optimizer  - solved problem         : the dual        \n",
      "Optimizer  - Constraints            : 3407\n",
      "Optimizer  - Cones                  : 1\n",
      "Optimizer  - Scalar variables       : 89050             conic                  : 1706            \n",
      "Optimizer  - Semi-definite variables: 0                 scalarized             : 0               \n",
      "Factor     - setup time             : 0.10              dense det. time        : 0.00            \n",
      "Factor     - ML order time          : 0.04              GP order time          : 0.00            \n",
      "Factor     - nonzeros before factor : 2.70e+05          after factor           : 4.31e+05        \n",
      "Factor     - dense dim.             : 2                 flops                  : 6.82e+07        \n",
      "ITE PFEAS    DFEAS    GFEAS    PRSTATUS   POBJ              DOBJ              MU       TIME  \n",
      "0   0.0e+00  7.8e+01  2.0e+00  0.00e+00   -1.000000000e+00  0.000000000e+00   1.0e+00  0.50  \n",
      "1   1.1e-15  6.5e+01  1.5e+00  2.36e+00   -6.141057270e-01  4.463352039e-02   8.4e-01  0.60  \n",
      "2   2.2e-14  4.8e+01  7.5e-01  2.50e+00   -3.531994941e-01  1.085489967e-02   6.2e-01  0.65  \n",
      "3   3.5e-14  4.1e+01  4.3e-01  3.23e+00   -2.404669334e-01  -6.685137121e-03  5.3e-01  0.71  \n",
      "4   5.0e-14  3.1e+01  2.2e-01  3.06e+00   -1.131293093e-01  2.407073861e-04   4.0e-01  0.76  \n",
      "5   3.9e-14  2.8e+01  1.7e-01  2.33e+00   -8.460976138e-02  3.331226118e-03   3.6e-01  0.82  \n",
      "6   3.6e-14  1.3e+01  5.1e-02  2.10e+00   -1.512522783e-02  1.249669349e-02   1.7e-01  0.87  \n",
      "7   4.0e-14  9.6e+00  3.0e-02  1.39e+00   -5.165028116e-03  1.439067266e-02   1.2e-01  0.93  \n",
      "8   5.2e-14  4.8e+00  1.0e-02  1.22e+00   9.304191024e-03   1.934992905e-02   6.2e-02  0.98  \n",
      "9   5.7e-13  3.1e+00  5.2e-03  1.02e+00   1.749173031e-02   2.434107898e-02   4.0e-02  1.04  \n",
      "10  2.3e-13  1.8e+00  2.3e-03  9.53e-01   2.698263540e-02   3.142350169e-02   2.4e-02  1.09  \n",
      "11  2.1e-13  1.3e+00  1.3e-03  8.88e-01   3.392225704e-02   3.717727353e-02   1.6e-02  1.15  \n",
      "12  3.3e-13  8.3e-01  7.0e-04  8.63e-01   4.180848455e-02   4.409852793e-02   1.1e-02  1.20  \n",
      "13  3.8e-13  7.0e-01  5.5e-04  8.49e-01   4.574488620e-02   4.776270789e-02   9.1e-03  1.25  \n",
      "14  2.4e-13  4.6e-01  2.9e-04  8.30e-01   5.716911857e-02   5.857471570e-02   5.9e-03  1.31  \n",
      "15  1.1e-12  3.3e-01  1.8e-04  7.62e-01   7.050564655e-02   7.160080065e-02   4.2e-03  1.36  \n",
      "16  1.5e-11  1.8e-01  8.0e-05  6.65e-01   1.108217725e-01   1.115262930e-01   2.3e-03  1.42  \n",
      "17  6.4e-11  1.1e-01  4.6e-05  3.69e-01   2.237223288e-01   2.242588805e-01   1.4e-03  1.47  \n",
      "18  4.6e-11  8.1e-02  3.3e-05  1.56e-01   2.922184515e-01   2.926768283e-01   1.0e-03  1.52  \n",
      "19  3.6e-11  6.2e-02  2.0e-05  8.30e-01   4.344072460e-01   4.347694347e-01   8.0e-04  1.58  \n",
      "20  2.1e-11  3.5e-02  9.2e-06  5.43e-01   6.135738745e-01   6.138091973e-01   4.5e-04  1.63  \n",
      "21  1.8e-11  3.1e-02  7.6e-06  7.14e-01   6.601530541e-01   6.603644977e-01   3.9e-04  1.69  \n",
      "22  1.3e-11  2.2e-02  4.6e-06  7.58e-01   7.595637684e-01   7.597251450e-01   2.9e-04  1.74  \n",
      "23  8.1e-12  1.4e-02  2.1e-06  8.55e-01   8.800970034e-01   8.801999529e-01   1.8e-04  1.79  \n",
      "24  6.9e-12  1.2e-02  1.6e-06  9.55e-01   9.145538704e-01   9.146417461e-01   1.5e-04  1.85  \n",
      "25  4.3e-12  7.4e-03  8.2e-07  9.77e-01   9.893057082e-01   9.893624213e-01   9.5e-05  1.95  \n",
      "26  2.5e-12  5.0e-03  4.5e-07  1.02e+00   1.038272206e+00   1.038310647e+00   6.5e-05  2.01  \n",
      "27  2.1e-12  4.5e-03  3.8e-07  1.05e+00   1.048406128e+00   1.048440958e+00   5.9e-05  2.07  \n",
      "28  1.6e-12  3.5e-03  2.6e-07  1.04e+00   1.071427658e+00   1.071454521e+00   4.5e-05  2.12  \n",
      "29  1.2e-12  2.6e-03  1.6e-07  1.06e+00   1.092894203e+00   1.092913551e+00   3.3e-05  2.18  \n",
      "30  9.1e-13  1.9e-03  9.5e-08  1.07e+00   1.108753578e+00   1.108767448e+00   2.4e-05  2.23  \n",
      "31  1.1e-12  1.5e-03  6.9e-08  1.07e+00   1.116278542e+00   1.116289728e+00   1.9e-05  2.28  \n",
      "32  1.4e-12  1.3e-03  5.3e-08  1.07e+00   1.121315452e+00   1.121324768e+00   1.6e-05  2.34  \n",
      "33  3.5e-12  9.2e-04  3.3e-08  1.07e+00   1.128253820e+00   1.128260587e+00   1.2e-05  2.39  \n",
      "34  4.3e-12  8.2e-04  2.7e-08  1.06e+00   1.130376009e+00   1.130381999e+00   1.1e-05  2.44  \n",
      "35  8.0e-12  5.9e-04  1.6e-08  1.06e+00   1.135074037e+00   1.135078319e+00   7.6e-06  2.49  \n",
      "36  8.8e-12  5.5e-04  1.5e-08  1.06e+00   1.135881141e+00   1.135885131e+00   7.1e-06  2.55  \n",
      "37  8.9e-12  5.5e-04  1.5e-08  1.06e+00   1.135884662e+00   1.135888635e+00   7.1e-06  2.60  \n",
      "38  1.3e-11  3.7e-04  7.8e-09  1.06e+00   1.139573872e+00   1.139576505e+00   4.7e-06  2.66  \n",
      "39  1.9e-11  2.9e-04  5.5e-09  1.05e+00   1.141105158e+00   1.141107233e+00   3.7e-06  2.72  \n",
      "40  2.6e-11  2.1e-04  3.3e-09  1.05e+00   1.142596596e+00   1.142598096e+00   2.7e-06  2.77  \n",
      "41  3.4e-11  1.7e-04  2.4e-09  1.04e+00   1.143308390e+00   1.143309607e+00   2.2e-06  2.82  \n",
      "42  5.5e-11  1.3e-04  1.5e-09  1.04e+00   1.144112070e+00   1.144112971e+00   1.6e-06  2.87  \n",
      "43  7.4e-11  6.9e-05  6.1e-10  1.04e+00   1.145139126e+00   1.145139613e+00   8.9e-07  2.93  \n",
      "44  1.2e-10  5.6e-05  4.5e-10  1.03e+00   1.145349965e+00   1.145350361e+00   7.3e-07  2.98  \n",
      "45  2.8e-10  3.1e-05  1.8e-10  1.03e+00   1.145753323e+00   1.145753544e+00   4.0e-07  3.04  \n",
      "46  3.4e-10  2.5e-05  1.3e-10  1.02e+00   1.145853158e+00   1.145853331e+00   3.2e-07  3.09  \n",
      "47  4.1e-10  2.0e-05  9.4e-11  1.02e+00   1.145919509e+00   1.145919652e+00   2.6e-07  3.20  \n",
      "48  7.0e-10  1.1e-05  3.8e-11  1.02e+00   1.146048018e+00   1.146048097e+00   1.4e-07  3.26  \n",
      "49  1.0e-09  1.0e-05  2.8e-11  1.02e+00   1.146074160e+00   1.146074225e+00   1.2e-07  3.32  \n",
      "50  1.2e-09  7.4e-06  2.1e-11  1.03e+00   1.146092727e+00   1.146092780e+00   9.8e-08  3.37  \n",
      "51  1.6e-09  6.2e-06  1.6e-11  9.80e-01   1.146110179e+00   1.146110222e+00   8.0e-08  3.42  \n",
      "52  3.5e-09  3.4e-06  6.3e-12  1.01e+00   1.146142888e+00   1.146142912e+00   4.4e-08  3.48  \n",
      "53  6.2e-09  1.9e-06  3.1e-12  1.00e+00   1.146155761e+00   1.146155776e+00   2.8e-08  3.53  \n",
      "Optimizer terminated. Time: 3.64    \n",
      "\n",
      "\n",
      "Interior-point solution summary\n",
      "  Problem status  : PRIMAL_AND_DUAL_FEASIBLE\n",
      "  Solution status : OPTIMAL\n",
      "  Primal.  obj: 1.1461557597e+00    nrm: 3e+01    Viol.  con: 3e-15    var: 9e-09    cones: 0e+00  \n",
      "  Dual.    obj: 1.1461557758e+00    nrm: 8e+01    Viol.  con: 0e+00    var: 2e-05    cones: 0e+00  \n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 23 10:39:10 AM: Problem status: optimal\n",
      "(CVXPY) Jun 23 10:39:10 AM: Optimal value: 1.146e+00\n",
      "(CVXPY) Jun 23 10:39:10 AM: Compilation took 2.808e+01 seconds\n",
      "(CVXPY) Jun 23 10:39:10 AM: Solver (including time spent in interface) took 4.063e+00 seconds\n",
      "Optimal value: 1.146149680911496\n",
      "Variable var0: value [2.23539651e+00 2.60246663e-02 5.58018245e-03 ... 3.19465758e-08\n",
      " 3.52233153e-09 2.05992729e-09]\n"
     ]
    }
   ],
   "source": [
    "## We run the optimiser to get the transports between water masses and the T,S mixed and T,S adjustment\n",
    "result = MTM.optimise(tracers, volumes, constraints, transport, transport2, weights)\n",
    "\n",
    "g_ij = result['g_ij'] ## An [N x N] matrix of transports between WMs\n",
    "Mixing = result['Mixing'] ## An [M x N] matrix of dtracer mixing for each WM\n",
    "Adjustment = result['Adjustment'] ## An [M x N] matrix of dtracer adjustment for each WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if Opt_twice:\n",
    "#     '''constraint = [G@Q = V2*C2 - G@C2]\n",
    "#         cost = cp.sum_squares( Q * volume/area )\n",
    "\n",
    "#         where C1 is the initial and C2 is the final tracer concentrations.'''\n",
    "#     result = MTM.optimise(tracers, volumes, constraints, weights)\n",
    "\n",
    "#     g_ij = result['g_ij'] ## An [N x N] matrix of transports between WMs\n",
    "#     Mixing = result['Mixing'] ## An [M x N] matrix of dtracer mixing for each WM\n",
    "#     Adjustment = result['Adjustment'] ## An [M x N] matrix of dtracer adjustment for each WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Break down the Mixing and Adjustment matrices into their constituent tracers\n",
    "dT_mixing = Mixing[1,:]\n",
    "dS_mixing = Mixing[0,:]\n",
    "dS_adj = Adjustment[0,:]\n",
    "dT_adj = Adjustment[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## E) Save Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dT_mixing = xr.DataArray(data = dT_mixing, dims = [\"WM_number\"],\n",
    "                           coords=dict(WM_number = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Temperature Mixing\", units=\"\\Delta K\", variable_id=\"EN4 Tmix\"))\n",
    "da_dS_mixing = xr.DataArray(data = dS_mixing, dims = [\"WM_number\"],\n",
    "                           coords=dict(WM_number = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Salinity Mixing\", units=\"\\Delta g/kg\", variable_id=\"EN4 Smix\"))\n",
    "da_dT_adjustment = xr.DataArray(data = dT_adj, dims = [\"WM_number\"],\n",
    "                           coords=dict(WM_number = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Temperature Adjustment\", units=\"\\Delta K\", variable_id=\"EN4 Tadj\"))\n",
    "da_dS_adjustment = xr.DataArray(data = dS_adj, dims = [\"WM_number\"],\n",
    "                           coords=dict(WM_number = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Salinity Adjustment\", units=\"\\Delta g/kg\", variable_id=\"EN4 Sadj\"))\n",
    "da_gij = xr.DataArray(data = g_ij*volnorming, dims = [\"WM_initial\", \"WM_final\"],\n",
    "                           coords=dict(WM_initial = np.arange(0,N), WM_final = np.arange(0,N)),\n",
    "                        attrs=dict(description=\"Volume transport\", units=\"m^3\", variable_id=\"EN4 Gij\"))\n",
    "\n",
    "## Create xarray DataSet that will hold all these DataArrays\n",
    "ds_BSP = xr.Dataset()\n",
    "ds_BSP['dT_mixing'] = da_dT_mixing\n",
    "ds_BSP['dS_mixing'] = da_dS_mixing\n",
    "ds_BSP['dT_adjustment'] = da_dT_adjustment\n",
    "ds_BSP['dS_adjustment'] = da_dS_adjustment\n",
    "ds_BSP['gij'] = da_gij\n",
    "\n",
    "if SF:\n",
    "   ds_BSP.to_netcdf('Optimisation_results/Optimal_result_ACCESS.nc', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00ec6b5807eb4cae4bdd23e758d78199b5749ea4aa251c45b926838befc3bdc7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
